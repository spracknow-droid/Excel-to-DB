import streamlit as st
import pandas as pd
import sqlite3
import os
import tempfile
import re

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Excel & DB Merger", layout="wide")

st.title("ğŸ“Š í†µí•© ë°ì´í„° ë³€í™˜ê¸° (ì—…ë¡œë“œ ì„¹ì…˜ ê¸°ì¤€ ì»¬ëŸ¼ ìˆ˜ì •)")
st.info("ğŸ’¡ ì»¬ëŸ¼ëª… ë³€ê²½ ë° ìˆ˜ì‹ ê³„ì‚°ì€ ì˜¤ì§ '1ï¸âƒ£ íŒë§¤ê³„íš' ì„¹ì…˜ì— ì—…ë¡œë“œëœ íŒŒì¼ì—ë§Œ ì ìš©ë©ë‹ˆë‹¤.")

all_data = []

# [ê³µí†µ ë¡œì§] ë°ì´í„° êµ¬ë¶„(Tagging) í•¨ìˆ˜
def add_data_tag(df):
    if df is None or df.empty:
        return df
    
    # 1. ì „í‘œë²ˆí˜¸ ìœ ë¬´ì— ë”°ë¥¸ ë°ì´í„° êµ¬ë¶„ (ì‚¬ìš©ì ì§€ì‹œì‚¬í•­)
    if 'ìˆ˜ìµì„±ê³„íšì „í‘œë²ˆí˜¸' in df.columns:
        is_plan = df['ìˆ˜ìµì„±ê³„íšì „í‘œë²ˆí˜¸'].notnull() & (df['ìˆ˜ìµì„±ê³„íšì „í‘œë²ˆí˜¸'].astype(str).str.strip() != "")
        df.loc[is_plan, '__ë°ì´í„°êµ¬ë¶„__'] = "íŒë§¤ê³„íš"
        df.loc[~is_plan, '__ë°ì´í„°êµ¬ë¶„__'] = "íŒë§¤ì‹¤ì "
    else:
        df['__ë°ì´í„°êµ¬ë¶„__'] = "íŒë§¤ì‹¤ì "
    return df

# [ê³µí†µ ë¡œì§] 'No' ì»¬ëŸ¼ ê¸°ë°˜ ìœ íš¨ ë°ì´í„° í•„í„°ë§ í•¨ìˆ˜
def filter_invalid_rows(df, filename):
    if 'No' in df.columns:
        initial_len = len(df)
        # 'No' ì»¬ëŸ¼ì´ NaN(ë¹„ì–´ìˆìŒ)ì´ê±°ë‚˜ ê³µë°±ì¸ í–‰ ì œê±°
        df = df.dropna(subset=['No'])
        df = df[df['No'].astype(str).str.strip() != ""]
        final_len = len(df)
        
        if initial_len > final_len:
            st.warning(f"âš ï¸ {filename}: 'No' ê°’ì´ ì—†ëŠ” {initial_len - final_len}ê°œì˜ í–‰ì´ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return df.reset_index(drop=True)

# --- ì‚¬ì´ë“œë°”: 3ê°œ ì—…ë¡œë“œ ì„¹ì…˜ ---
st.sidebar.header("ğŸ“ ë°ì´í„° ì†ŒìŠ¤ ì—…ë¡œë“œ")
uploaded_plans = st.sidebar.file_uploader("1ï¸âƒ£ íŒë§¤ê³„íš (xlsx)", type=["xlsx"], accept_multiple_files=True)
uploaded_results = st.sidebar.file_uploader("2ï¸âƒ£ íŒë§¤ì‹¤ì  (xlsx)", type=["xlsx"], accept_multiple_files=True)
uploaded_dbs = st.sidebar.file_uploader("3ï¸âƒ£ ê¸°ì¡´ SQLite (db)", type=["db"], accept_multiple_files=True)

if uploaded_plans or uploaded_results or uploaded_dbs:
    with st.status("ë¡œì§ ì ìš© ë° ë°ì´í„° ë³‘í•© ì¤‘...", expanded=True) as status:
        
        # [Step 1] íŒë§¤ê³„íš ì„¹ì…˜ (ì»¬ëŸ¼ ìˆ˜ì • ë¡œì§ ì ìš©)
        for file in uploaded_plans:
            try:
                df = pd.read_excel(file)
                df.columns = [str(c).strip() for c in df.columns] # ê³µë°± ì œê±°
                
                # 'No' ì»¬ëŸ¼ê°’ ì—†ëŠ” í–‰ ì‚­ì œ ë¡œì§ ì¶”ê°€
                df = filter_invalid_rows(df, file.name)
                
                # 1. ì»¬ëŸ¼ëª… ë³€ê²½ (í’ˆëª… -> í’ˆëª©ëª…, íŒë§¤ê¸ˆì•¡ -> ì¥ë¶€ê¸ˆì•¡)
                df = df.rename(columns={'í’ˆëª…': 'í’ˆëª©ëª…', 'íŒë§¤ê¸ˆì•¡': 'ì¥ë¶€ê¸ˆì•¡'})
                
                # 2. ì‹ ê·œ íŒë§¤ê¸ˆì•¡ ìƒì„± (íŒë§¤ìˆ˜ëŸ‰ * íŒë§¤ë‹¨ê°€)
                qty = pd.to_numeric(df.get('íŒë§¤ìˆ˜ëŸ‰', 0), errors='coerce').fillna(0)
                price = pd.to_numeric(df.get('íŒë§¤ë‹¨ê°€', 0), errors='coerce').fillna(0)
                df['íŒë§¤ê¸ˆì•¡'] = qty * price
                
                # 3. ë°ì´í„° êµ¬ë¶„ íƒœê·¸ ì¶”ê°€ (ì „í‘œë²ˆí˜¸ ê¸°ì¤€)
                df = add_data_tag(df)
                
                all_data.append(df)
                st.write(f"âœ… [ê³„íšì„¹ì…˜] {file.name} - ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e: st.error(f"Error ({file.name}): {e}")

        # [Step 2] íŒë§¤ì‹¤ì  ì„¹ì…˜ (ì›ë³¸ ì»¬ëŸ¼ ìœ ì§€)
        for file in uploaded_results:
            try:
                df = pd.read_excel(file)
                df.columns = [str(c).strip() for c in df.columns]
                
                # 'No' ì»¬ëŸ¼ê°’ ì—†ëŠ” í–‰ ì‚­ì œ ë¡œì§ ì¶”ê°€
                df = filter_invalid_rows(df, file.name)
                
                # ì»¬ëŸ¼ ìˆ˜ì • ì—†ì´ íƒœê·¸ë§Œ ì¶”ê°€
                df = add_data_tag(df)
                
                all_data.append(df)
                st.write(f"âœ… [ì‹¤ì ì„¹ì…˜] {file.name} - ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e: st.error(f"Error ({file.name}): {e}")

        # [Step 3] DB íŒŒì¼ (ì›ë³¸ ì™„ì „ ë³´ì¡´)
        for file in uploaded_dbs:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".db") as tmp_file:
                tmp_file.write(file.getvalue())
                tmp_path = tmp_file.name
            try:
                conn_old = sqlite3.connect(tmp_path)
                tables = pd.read_sql("SELECT name FROM sqlite_master WHERE type='table';", conn_old)
                for target_table in tables['name']:
                    df_db = pd.read_sql(f"SELECT * FROM {target_table}", conn_old)
                    all_data.append(df_db)
                conn_old.close()
                st.write(f"âœ… [DB] {file.name} - ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            finally:
                if os.path.exists(tmp_path): os.remove(tmp_path)

        # [Step 4] ë³‘í•© ë° ìµœì¢… ì •ì œ
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # SQL/Streamlit í˜¸í™˜ì„ ìœ„í•œ ì»¬ëŸ¼ ì¤‘ë³µ í•´ê²° ë¡œì§
            new_cols = []
            col_counts = {}
            for col in combined_df.columns:
                clean_name = re.sub(r'\W+', '_', str(col)).strip('_')
                if clean_name in col_counts:
                    col_counts[clean_name] += 1
                    final_name = f"{clean_name}_{col_counts[clean_name]}"
                else:
                    col_counts[clean_name] = 0
                    final_name = clean_name
                new_cols.append(final_name)
            combined_df.columns = new_cols

            # ë°ì´í„° íƒ€ì… í†µì¼ ë° ì¤‘ë³µ ì œê±°
            cols_to_fix = combined_df.select_dtypes(include=['object']).columns
            for col in cols_to_fix:
                combined_df[col] = combined_df[col].astype(str).replace(['nan', 'None'], '')
            combined_df = combined_df.drop_duplicates()

            # [Step 5] í†µí•© DB ìƒì„±
            db_filename = "sales_integrated_final.db"
            if os.path.exists(db_filename): os.remove(db_filename)
            conn_new = sqlite3.connect(db_filename)
            combined_df.to_sql("total_data", conn_new, index=False, if_exists="replace")
            conn_new.close()
            
            status.update(label="ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!", state="complete", expanded=False)
            
            st.subheader("ğŸ“Š í†µí•© ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(combined_df.head(10))
            
            with open(db_filename, "rb") as f:
                st.download_button("ğŸ’¾ í†µí•© DB ë‹¤ìš´ë¡œë“œ", f, file_name=db_filename)
