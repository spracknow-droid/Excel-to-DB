import streamlit as st
import pandas as pd
import sqlite3
import os
import tempfile
import io
import processor as proc
import constants as const

st.set_page_config(page_title="Sales Data Integrator", layout="wide")
st.title("ğŸ“Š íŒë§¤ ë°ì´í„° í†µí•© ê´€ë¦¬ ì‹œìŠ¤í…œ")
st.info("ğŸ’¡ ê³„íšê³¼ ì‹¤ì  ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ì—¬ ì €ì¥í•˜ê³  ë¹„êµ ë¶„ì„ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤.")

# ë°ì´í„° ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸ ë¶„ë¦¬
plan_data_list = []
result_data_list = []

# --- ì‚¬ì´ë“œë°”: ë°ì´í„° ì—…ë¡œë“œ [6, 7] ---
st.sidebar.header("ğŸ“ ë°ì´í„° ì†ŒìŠ¤ ì—…ë¡œë“œ")
uploaded_plans = st.sidebar.file_uploader("1ï¸âƒ£ íŒë§¤ê³„íš (xlsx)", type=["xlsx"], accept_multiple_files=True)
uploaded_results = st.sidebar.file_uploader("2ï¸âƒ£ íŒë§¤ì‹¤ì  (xlsx)", type=["xlsx"], accept_multiple_files=True)
uploaded_dbs = st.sidebar.file_uploader("3ï¸âƒ£ ê¸°ì¡´ SQLite (db)", type=["db"], accept_multiple_files=True)

if uploaded_plans or uploaded_results or uploaded_dbs:
    with st.status("ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ í…Œì´ë¸” ìƒì„± ì¤‘...", expanded=True) as status:
        
        # [Step 1] íŒë§¤ê³„íš ì²˜ë¦¬ [7, 8]
        for file in uploaded_plans:
            try:
                df = pd.read_excel(file, dtype={'ë§¤ì¶œì²˜': str, 'í’ˆëª©ì½”ë“œ': str})
                df.columns = [str(c).strip() for c in df.columns]
                df = df.rename(columns=const.PLAN_RENAME_MAP)
                if 'No' in df.columns:
                    df = df.dropna(subset=['No'])
                
                df = proc.format_specific_columns(df)
                df = proc.clean_date_columns(df)
                
                # ê³„íš ì „ìš© ê³„ì‚° ë¡œì§ [8]
                qty = pd.to_numeric(df.get('ìˆ˜ëŸ‰', 0), errors='coerce').fillna(0)
                price = pd.to_numeric(df.get('íŒë§¤ë‹¨ê°€', 0), errors='coerce').fillna(0)
                df['íŒë§¤ê¸ˆì•¡'] = qty * price
                
                plan_data_list.append(df)
                st.write(f"âœ… [ê³„íš] {file.name}")
            except Exception as e: st.error(f"ê³„íš íŒŒì¼ ì—ëŸ¬ ({file.name}): {e}")

        # [Step 2] íŒë§¤ì‹¤ì  ì²˜ë¦¬ [9]
        for file in uploaded_results:
            try:
                df = pd.read_excel(file, dtype={'ë§¤ì¶œì²˜': str, 'í’ˆëª©': str})
                df.columns = [str(c).strip() for c in df.columns]
                if 'No' in df.columns:
                    df = df.dropna(subset=['No'])
                
                df = proc.format_specific_columns(df)
                df = proc.clean_date_columns(df)
                result_data_list.append(df)
                st.write(f"âœ… [ì‹¤ì ] {file.name}")
            except Exception as e: st.error(f"ì‹¤ì  íŒŒì¼ ì—ëŸ¬ ({file.name}): {e}")

        # [Step 3] ê¸°ì¡´ DB ë¡œë“œ ë° ë¶„ë¥˜ [10]
        for file in uploaded_dbs:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".db") as tmp_file:
                tmp_file.write(file.getvalue())
                tmp_path = tmp_file.name
            try:
                conn_old = sqlite3.connect(tmp_path)
                # ê¸°ì¡´ DBì˜ í…Œì´ë¸”ë³„ë¡œ ë¶„ë¥˜í•˜ì—¬ ë¡œë“œ
                for table in ["plan_data", "result_data"]:
                    try:
                        df_db = pd.read_sql(f"SELECT * FROM {table}", conn_old)
                        if table == "plan_data": plan_data_list.append(df_db)
                        else: result_data_list.append(df_db)
                    except: pass
                conn_old.close()
                st.write(f"âœ… [ê¸°ì¡´ DB] {file.name} ë¡œë“œ ì™„ë£Œ")
            finally:
                if os.path.exists(tmp_path): os.remove(tmp_path)

        # [Step 4] ë°ì´í„° í†µí•© ë° ë¶„ì„ í…Œì´ë¸” ìƒì„± [11]
        final_plan_df = proc.finalize_combined_df(plan_data_list)
        final_result_df = proc.finalize_combined_df(result_data_list)
        analysis_df = proc.create_analysis_df(final_plan_df, final_result_df)

        # [Step 5] DB ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ [11, 12]
        if final_plan_df is not None or final_result_df is not None:
            conn_new = sqlite3.connect(const.DB_FILENAME)
            if final_plan_df is not None: final_plan_df.to_sql("plan_data", conn_new, index=False, if_exists="replace")
            if final_result_df is not None: final_result_df.to_sql("result_data", conn_new, index=False, if_exists="replace")
            if analysis_df is not None: analysis_df.to_sql("analysis_data", conn_new, index=False, if_exists="replace")
            conn_new.close()

            # ì—‘ì…€ ë©€í‹° ì‹œíŠ¸ ìƒì„± [12]
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                if final_plan_df is not None: final_plan_df.to_excel(writer, sheet_name='Plan', index=False)
                if final_result_df is not None: final_result_df.to_excel(writer, sheet_name='Result', index=False)
                if analysis_df is not None: analysis_df.to_excel(writer, sheet_name='Analysis', index=False)
            excel_data = output.getvalue()

            status.update(label="âœ… ì²˜ë¦¬ ì™„ë£Œ!", state="complete", expanded=False)
            
            # UI ì¶œë ¥ ë° ë‹¤ìš´ë¡œë“œ [12]
            st.success("ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            if analysis_df is not None:
                st.subheader("ğŸ“Š ê³„íš ëŒ€ë¹„ ì‹¤ì  ë¶„ì„ (ë¯¸ë¦¬ë³´ê¸°)")
                st.dataframe(analysis_df.head(10))

            c1, c2 = st.columns(2)
            with c1:
                with open(const.DB_FILENAME, "rb") as f:
                    st.download_button("ğŸ’¾ í†µí•© DB ë‹¤ìš´ë¡œë“œ", data=f, file_name=const.DB_FILENAME, use_container_width=True)
            with c2:
                st.download_button("ğŸ“‘ í†µí•© Excel ë‹¤ìš´ë¡œë“œ", data=excel_data, file_name=const.EXCEL_FILENAME, use_container_width=True)
