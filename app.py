import streamlit as st
import pandas as pd
import sqlite3
import os
import tempfile

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Excel & DB Merger", layout="wide")

st.title("ğŸ“Š í†µí•© ë°ì´í„° ë³€í™˜ê¸° (ì „í‘œë²ˆí˜¸ ê¸°ì¤€ ë¶„ë¥˜)")
st.markdown("'ìˆ˜ìµì„±ê³„íšì „í‘œë²ˆí˜¸'ì— ê°’ì´ ìˆìœ¼ë©´ íŒë§¤ê³„íš(í’ˆëª…/íŒë§¤ê¸ˆì•¡ ë³€ê²½ ë° ì‹ ê·œ ê¸ˆì•¡ ê³„ì‚°), ì—†ìœ¼ë©´ íŒë§¤ì‹¤ì ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.")

# --- ì‚¬ì´ë“œë°”: 3ê°œ ì—…ë¡œë“œ ì„¹ì…˜ ---
st.sidebar.header("ğŸ“ ë°ì´í„° ì†ŒìŠ¤ ì—…ë¡œë“œ")

uploaded_plans = st.sidebar.file_uploader(
    "1ï¸âƒ£ íŒë§¤ê³„íš (xlsx)", 
    type=["xlsx"], 
    accept_multiple_files=True,
    key="plan_uploader"
)

uploaded_results = st.sidebar.file_uploader(
    "2ï¸âƒ£ íŒë§¤ì‹¤ì  (xlsx)", 
    type=["xlsx"], 
    accept_multiple_files=True,
    key="result_uploader"
)

uploaded_dbs = st.sidebar.file_uploader(
    "3ï¸âƒ£ ê¸°ì¡´ SQLite (db)", 
    type=["db"], 
    accept_multiple_files=True,
    key="db_uploader"
)

all_data = []

# ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
def process_classification(df):
    if 'ìˆ˜ìµì„±ê³„íšì „í‘œë²ˆí˜¸' in df.columns:
        # ê°’ì´ ìˆëŠ” ê²½ìš° (íŒë§¤ê³„íš)
        is_plan = df['ìˆ˜ìµì„±ê³„íšì „í‘œë²ˆí˜¸'].notnull() & (df['ìˆ˜ìµì„±ê³„íšì „í‘œë²ˆí˜¸'].astype(str).str.strip() != "")
        
        # [íŒë§¤ê³„íš ë°ì´í„° ì²˜ë¦¬]
        df_plan = df[is_plan].copy()
        if not df_plan.empty:
            # 1. ì»¬ëŸ¼ëª… ë³€ê²½ (ê¸°ì¡´ íŒë§¤ê¸ˆì•¡ -> ì¥ë¶€ê¸ˆì•¡)
            df_plan = df_plan.rename(columns={'í’ˆëª…': 'í’ˆëª©ëª…', 'íŒë§¤ê¸ˆì•¡': 'ì¥ë¶€ê¸ˆì•¡'})
            
            # 2. ì‹ ê·œ íŒë§¤ê¸ˆì•¡ ìƒì„± (íŒë§¤ìˆ˜ëŸ‰ * íŒë§¤ë‹¨ê°€)
            # ìˆ˜ì¹˜ ë°ì´í„°ê°€ ì•„ë‹Œ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ìˆ«ìë¡œ ë³€í™˜ í›„ ê³„ì‚°
            qty = pd.to_numeric(df_plan.get('íŒë§¤ìˆ˜ëŸ‰', 0), errors='coerce').fillna(0)
            price = pd.to_numeric(df_plan.get('íŒë§¤ë‹¨ê°€', 0), errors='coerce').fillna(0)
            df_plan['íŒë§¤ê¸ˆì•¡'] = qty * price
            
            df_plan['__ë°ì´í„°êµ¬ë¶„__'] = "íŒë§¤ê³„íš"
            all_data.append(df_plan)
            
        # [íŒë§¤ì‹¤ì  ë°ì´í„° ì²˜ë¦¬]
        df_result = df[~is_plan].copy()
        if not df_result.empty:
            df_result['__ë°ì´í„°êµ¬ë¶„__'] = "íŒë§¤ì‹¤ì "
            all_data.append(df_result)
    else:
        # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ íŒë§¤ì‹¤ì ìœ¼ë¡œ ë¶„ë¥˜
        df['__ë°ì´í„°êµ¬ë¶„__'] = "íŒë§¤ì‹¤ì "
        all_data.append(df)

if uploaded_plans or uploaded_results or uploaded_dbs:
    with st.status("íŒŒì¼ ì½ê¸° ë° ë¶„ë¥˜ ë¡œì§ ì ìš© ì¤‘...", expanded=True) as status:
        
        # [Step 1] íŒë§¤ê³„íš ì„¹ì…˜ íŒŒì¼ ì²˜ë¦¬
        for file in uploaded_plans:
            try:
                df = pd.read_excel(file)
                process_classification(df)
                st.write(f"âœ… [ê³„íšì„¹ì…˜] {file.name} ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                st.error(f"âŒ {file.name} ì½ê¸° ì‹¤íŒ¨: {e}")

        # [Step 2] íŒë§¤ì‹¤ì  ì„¹ì…˜ íŒŒì¼ ì²˜ë¦¬
        for file in uploaded_results:
            try:
                df = pd.read_excel(file)
                process_classification(df)
                st.write(f"âœ… [ì‹¤ì ì„¹ì…˜] {file.name} ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                st.error(f"âŒ {file.name} ì½ê¸° ì‹¤íŒ¨: {e}")

        # [Step 3] SQLite DB ì²˜ë¦¬
        for file in uploaded_dbs:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".db") as tmp_file:
                tmp_file.write(file.getvalue())
                tmp_path = tmp_file.name
            try:
                conn_old = sqlite3.connect(tmp_path)
                tables = pd.read_sql("SELECT name FROM sqlite_master WHERE type='table';", conn_old)
                for target_table in tables['name']:
                    df_db = pd.read_sql(f"SELECT * FROM {target_table}", conn_old)
                    process_classification(df_db)
                st.write(f"âœ… [DB] {file.name} ë¡œë“œ ë° ë¶„ë¥˜ ì™„ë£Œ")
                conn_old.close()
            except Exception as e:
                st.error(f"âŒ {file.name} ë¡œë“œ ì‹¤íŒ¨: {e}")
            finally:
                if os.path.exists(tmp_path):
                    os.remove(tmp_path)

        # [Step 4] ë³‘í•© ë° ì¤‘ë³µ ì œê±°
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            
            for col in combined_df.columns:
                if combined_df[col].dtype == 'object':
                    combined_df[col] = combined_df[col].astype(str)
            
            initial_count = len(combined_df)
            combined_df = combined_df.drop_duplicates()
            final_count = len(combined_df)
            
            st.write(f"ğŸ“ ì „ì²´ í†µí•© ê²°ê³¼: {final_count}í–‰ (ì¤‘ë³µ {initial_count - final_count}í–‰ ì‚­ì œë¨)")

            # [Step 5] DB íŒŒì¼ ìƒì„±
            db_filename = "integrated_sales_data.db"
            if os.path.exists(db_filename):
                os.remove(db_filename)
                
            conn_new = sqlite3.connect(db_filename)
            combined_df.to_sql("total_data", conn_new, index=False, if_exists="replace")
            conn_new.close()
            
            status.update(label="í†µí•© ì™„ë£Œ!", state="complete", expanded=False)

            st.subheader("ğŸ“Š í†µí•© ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(combined_df.head(10))

            with open(db_filename, "rb") as f:
                st.download_button(
                    label="ğŸ’¾ í†µí•©ëœ SQLite DB ë‹¤ìš´ë¡œë“œ",
                    data=f,
                    file_name=db_filename,
                    mime="application/octet-stream"
                )
else:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
