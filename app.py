import streamlit as st
import pandas as pd
import sqlite3
import os
import tempfile
import re
import io

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Excel & DB Merger", layout="wide")

st.title("ğŸ“Š íŒë§¤ ë°ì´í„°(ê³„íš/ì‹¤ì ) SQLite DB ë³€í™˜ê¸°")
st.info("ğŸ’¡ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒë§¤ ë°ì´í„°(ê³„íš/ì‹¤ì )ë¥¼ í†µí•©í•˜ì—¬ SQLite DBë¡œ ë³€í™˜í•˜ëŠ” í˜ì´ì§€ì…ë‹ˆë‹¤.")

all_data = []

# [í•¨ìˆ˜] íŠ¹ì • ì»¬ëŸ¼ íƒ€ì…ì„ ë¬¸ìì—´ë¡œ ê³ ì • ë° ë°ì´í„° í´ë¦¬ë‹
def format_specific_columns(df):
    """'ë§¤ì¶œì²˜' ë“± ì½”ë“œ ì„±ê²©ì˜ ì»¬ëŸ¼ì„ ê¹¨ë—í•œ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    target_cols = ['ë§¤ì¶œì²˜', 'ìˆ˜ê¸ˆì²˜', 'ë‚©í’ˆì²˜', 'í’ˆëª©', 'í’ˆëª©ëª…', 'í’ˆë²ˆ'] 
    for col in target_cols:
        if col in df.columns:
            df[col] = df[col].astype(str).replace(['nan', 'None', 'nan.0'], '')
            df[col] = df[col].apply(lambda x: x.split('.')[0] if x.endswith('.0') else x)
            df[col] = df[col].str.strip()
    return df

# [í•¨ìˆ˜] ë‚ ì§œ ì»¬ëŸ¼ì—ì„œ ì‹œê°„ ì •ë³´ë¥¼ ì œê±°í•˜ê³  YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ í†µì¼
def clean_date_columns(df):
    """ì—‘ì…€ì˜ '12:00:00 AM' ê°™ì€ ì‹œê°„ ì •ë³´ë¥¼ ì œê±°"""
    date_target_cols = ['ê³„íšë…„ì›”', 'ë§¤ì¶œì¼', 'ìˆ˜ê¸ˆì˜ˆì •ì¼', 'ì¶œê³ ì¼']
    for col in date_target_cols:
        if col in df.columns:
            # ë‚ ì§œí˜•ìœ¼ë¡œ ë³€í™˜ ì‹œë„ (ë³€í™˜ ì•ˆ ë˜ëŠ” ê°’ì€ NaT)
            df[col] = pd.to_datetime(df[col], errors='coerce')
            # YYYY-MM-DD í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜ (ë¹ˆ ê°’ì€ ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬)
            df[col] = df[col].dt.strftime('%Y-%m-%d').fillna('')
    return df

# [ê³µí†µ ë¡œì§] ë°ì´í„° êµ¬ë¶„(Tagging) í•¨ìˆ˜
def add_data_tag(df):
    if df is None or df.empty:
        return df
    
    tag_col = '__ë°ì´í„°êµ¬ë¶„__'
    if tag_col in df.columns:
        return df

    if 'ìˆ˜ìµì„±ê³„íšì „í‘œë²ˆí˜¸' in df.columns:
        is_plan = df['ìˆ˜ìµì„±ê³„íšì „í‘œë²ˆí˜¸'].notnull() & (df['ìˆ˜ìµì„±ê³„íšì „í‘œë²ˆí˜¸'].astype(str).str.strip() != "")
        df.loc[is_plan, tag_col] = "íŒë§¤ê³„íš"
        df.loc[~is_plan, tag_col] = "íŒë§¤ì‹¤ì "
    else:
        df[tag_col] = "íŒë§¤ì‹¤ì "
    return df

# [ê³µí†µ ë¡œì§] 'No' ì»¬ëŸ¼ ê¸°ë°˜ ìœ íš¨ ë°ì´í„° í•„í„°ë§ í•¨ìˆ˜
def filter_invalid_rows(df, filename):
    if 'No' in df.columns:
        initial_len = len(df)
        df = df.dropna(subset=['No'])
        df = df[df['No'].astype(str).str.strip() != ""]
        final_len = len(df)
        if initial_len > final_len:
            st.warning(f"âš ï¸ {filename}: 'No' ê°’ì´ ì—†ëŠ” {initial_len - final_len}ê°œì˜ í–‰ì´ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return df.reset_index(drop=True)
    return df

# --- ì‚¬ì´ë“œë°”: ë°ì´í„° ì—…ë¡œë“œ ---
st.sidebar.header("ğŸ“ ë°ì´í„° ì†ŒìŠ¤ ì—…ë¡œë“œ")
uploaded_plans = st.sidebar.file_uploader("1ï¸âƒ£ íŒë§¤ê³„íš (xlsx)", type=["xlsx"], accept_multiple_files=True)
uploaded_results = st.sidebar.file_uploader("2ï¸âƒ£ íŒë§¤ì‹¤ì  (xlsx)", type=["xlsx"], accept_multiple_files=True)
uploaded_dbs = st.sidebar.file_uploader("3ï¸âƒ£ ê¸°ì¡´ SQLite (db)", type=["db"], accept_multiple_files=True)

if uploaded_plans or uploaded_results or uploaded_dbs:
    with st.status("ë°ì´í„° í†µí•© ë° ìµœì í™” ì§„í–‰ ì¤‘...", expanded=True) as status:
        
        # [Step 1] íŒë§¤ê³„íš ì²˜ë¦¬
        for file in uploaded_plans:
            try:
                df = pd.read_excel(file, dtype={'ë§¤ì¶œì²˜': str, 'í’ˆëª©ì½”ë“œ': str})
                df.columns = [str(c).strip() for c in df.columns]

                # ì»¬ëŸ¼ëª… ë³€ê²½ (í’ˆëª©ì½”ë“œ -> í’ˆëª©, íŒë§¤ìˆ˜ëŸ‰ -> ìˆ˜ëŸ‰)
                df = df.rename(columns={
                    'í’ˆëª©ì½”ë“œ': 'í’ˆëª©',
                    'íŒë§¤ìˆ˜ëŸ‰': 'ìˆ˜ëŸ‰',
                    'í’ˆëª…': 'í’ˆëª©ëª…', 
                    'íŒë§¤ê¸ˆì•¡': 'ì¥ë¶€ê¸ˆì•¡'
                })

                df = format_specific_columns(df)
                df = clean_date_columns(df) # ğŸš€ ë‚ ì§œ ì •ì œ ì¶”ê°€
                df = filter_invalid_rows(df, file.name)
                
                # ìˆ˜ëŸ‰ ë° ì¥ë¶€ê¸ˆì•¡ ìˆ«ì ë³€í™˜
                qty = pd.to_numeric(df.get('ìˆ˜ëŸ‰', 0), errors='coerce').fillna(0)
                book_amt = pd.to_numeric(df.get('ì¥ë¶€ê¸ˆì•¡', 0), errors='coerce').fillna(0)
                
                # ì¥ë¶€ë‹¨ê°€ ìƒì„± (ì¥ë¶€ê¸ˆì•¡ / ìˆ˜ëŸ‰)
                df['ì¥ë¶€ë‹¨ê°€'] = book_amt / qty.replace(0, pd.NA)
                df['ì¥ë¶€ë‹¨ê°€'] = df['ì¥ë¶€ë‹¨ê°€'].fillna(0)
                
                # íŒë§¤ë‹¨ê°€ ê¸°ë°˜ íŒë§¤ê¸ˆì•¡ ì¬ê³„ì‚°
                price = pd.to_numeric(df.get('íŒë§¤ë‹¨ê°€', 0), errors='coerce').fillna(0)
                df['íŒë§¤ê¸ˆì•¡'] = qty * price
                
                df = add_data_tag(df)
                all_data.append(df)
                st.write(f"âœ… [ê³„íš] {file.name}")
            except Exception as e: st.error(f"Error ({file.name}): {e}")

        # [Step 2] íŒë§¤ì‹¤ì  ì²˜ë¦¬
        for file in uploaded_results:
            try:
                df = pd.read_excel(file, dtype={'ë§¤ì¶œì²˜': str, 'ìˆ˜ê¸ˆì²˜' : str, 'ë‚©í’ˆì²˜' : str, 'í’ˆëª©': str})
                df.columns = [str(c).strip() for c in df.columns]
                
                df = format_specific_columns(df)
                df = clean_date_columns(df) # ğŸš€ ë‚ ì§œ ì •ì œ ì¶”ê°€
                df = filter_invalid_rows(df, file.name)
                df = add_data_tag(df)
                all_data.append(df)
                st.write(f"âœ… [ì‹¤ì ] {file.name}")
            except Exception as e: st.error(f"Error ({file.name}): {e}")

        # [Step 3] ê¸°ì¡´ DB ë¡œë“œ (ì¶”ê°€ë¨)
        for file in uploaded_dbs:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".db") as tmp_file:
                tmp_file.write(file.getvalue())
                tmp_path = tmp_file.name
            try:
                conn_old = sqlite3.connect(tmp_path)
                tables = pd.read_sql("SELECT name FROM sqlite_master WHERE type='table';", conn_old)
                for target_table in tables['name']:
                    df_db = pd.read_sql(f"SELECT * FROM {target_table}", conn_old)
                    df_db = format_specific_columns(df_db)
                    df_db = clean_date_columns(df_db) # ğŸš€ ê¸°ì¡´ DB ë°ì´í„°ë„ ë‚ ì§œ ì •ì œ
                    all_data.append(df_db)
                conn_old.close()
                st.write(f"âœ… [ê¸°ì¡´ DB] {file.name}")
            finally:
                if os.path.exists(tmp_path): os.remove(tmp_path)

        # [Step 4] í†µí•© ë°ì´í„° ìµœì¢… ì •ì œ ë° ì €ì¥
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            
            clean_names = []
            for col in combined_df.columns:
                c_name = re.sub(r'[^a-zA-Z0-9ê°€-í£]', '_', str(col)).strip('_')
                c_name = re.sub(r'_+', '_', c_name)
                clean_names.append(c_name if c_name else "unnamed")
            combined_df.columns = clean_names

            duplicated_col_list = combined_df.columns[combined_df.columns.duplicated()].unique()
            if not duplicated_col_list.empty:
                for col_name in duplicated_col_list:
                    cols_to_merge = combined_df.loc[:, combined_df.columns == col_name]
                    merged_values = cols_to_merge.ffill(axis=1).iloc[:, -1]
                    combined_df = combined_df.loc[:, combined_df.columns != col_name]
                    combined_df[col_name] = merged_values
                st.info(f"ğŸ’¡ ì¤‘ë³µëœ ì»¬ëŸ¼({', '.join(duplicated_col_list)})ì„ ìë™ìœ¼ë¡œ í†µí•©í•˜ì˜€ìŠµë‹ˆë‹¤.")

            obj_cols = combined_df.select_dtypes(include=['object']).columns
            for col in obj_cols:
                combined_df[col] = combined_df[col].fillna('').astype(str).replace(['nan', 'None', 'nan.0'], '')
            
            combined_df = combined_df.drop_duplicates()

            db_filename = "sales_integrated_final.db"
            if os.path.exists(db_filename):
                try: os.remove(db_filename)
                except: pass
            
            conn_new = sqlite3.connect(db_filename)
            try:
                combined_df.to_sql("total_data", conn_new, index=False, if_exists="replace", chunksize=1000)
                conn_new.close()
                
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    combined_df.to_excel(writer, index=False, sheet_name='TotalData')
                excel_data = output.getvalue()

                status.update(label="âœ… í†µí•© ì™„ë£Œ!", state="complete", expanded=False)
                st.success(f"ğŸŠ ì´ **{len(combined_df):,}** í–‰ì˜ ë°ì´í„°ê°€ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.dataframe(combined_df.head(10))
                
                c1, c2 = st.columns(2)
                with c1:
                    with open(db_filename, "rb") as f:
                        st.download_button("ğŸ’¾ í†µí•© DB ë‹¤ìš´ë¡œë“œ", data=f, file_name=db_filename, use_container_width=True)
                with c2:
                    st.download_button("ğŸ“‘ í†µí•© Excel ë‹¤ìš´ë¡œë“œ", data=excel_data, file_name="sales_integrated_final.xlsx", use_container_width=True)
            except Exception as e:
                st.error(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
